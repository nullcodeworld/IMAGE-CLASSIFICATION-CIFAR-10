{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cifar10Updated.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQtKX1tcpeqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.datasets import cifar10\n",
        "from keras import regularizers\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XT7j9FdjqKo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    lrate = 0.001\n",
        "    if epoch > 75:\n",
        "        lrate = 0.0005\n",
        "    if epoch > 100:\n",
        "        lrate = 0.0003\n",
        "    return lrate\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vzz92n1EqNBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0s5yn4_qPdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#z-score\n",
        "mean = np.mean(x_train,axis=(0,1,2,3))\n",
        "std = np.std(x_train,axis=(0,1,2,3))\n",
        "x_train = (x_train-mean)/(std+1e-7)\n",
        "x_test = (x_test-mean)/(std+1e-7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eca_abIqR5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 10\n",
        "y_train = np_utils.to_categorical(y_train,num_classes)\n",
        "y_test = np_utils.to_categorical(y_test,num_classes)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me6ikZ-KqUiP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weight_decay = 1e-4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVzdcocoqXCH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O4kdF2nqaAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        " \n",
        "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNvd6ateqc6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FB5t0ytZqfkJ",
        "colab_type": "code",
        "outputId": "5e986b1e-3773-40f3-f0e8-046ca491f000",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 309,290\n",
            "Trainable params: 308,394\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Enqi-_9qh94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    )\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgsXmd_Xqk9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training\n",
        "batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG9GaN8rqnOS",
        "colab_type": "code",
        "outputId": "41a50869-584f-4d9b-a369-ff818aeb780f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 954
        }
      },
      "source": [
        "opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['accuracy'])\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\\\n",
        "                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=25,\\\n",
        "                    verbose=1,validation_data=(x_test,y_test),callbacks=[LearningRateScheduler(lr_schedule)])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "781/781 [==============================] - 591s 756ms/step - loss: 0.9848 - acc: 0.7873 - val_loss: 0.8704 - val_acc: 0.8033\n",
            "Epoch 2/25\n",
            "781/781 [==============================] - 589s 755ms/step - loss: 0.9995 - acc: 0.7889 - val_loss: 0.8783 - val_acc: 0.8036\n",
            "Epoch 3/25\n",
            "781/781 [==============================] - 592s 758ms/step - loss: 1.0198 - acc: 0.7882 - val_loss: 0.8383 - val_acc: 0.8354\n",
            "Epoch 4/25\n",
            "781/781 [==============================] - 597s 764ms/step - loss: 0.9931 - acc: 0.7942 - val_loss: 0.9801 - val_acc: 0.7890\n",
            "Epoch 5/25\n",
            "781/781 [==============================] - 593s 760ms/step - loss: 0.9818 - acc: 0.7940 - val_loss: 0.7634 - val_acc: 0.8350\n",
            "Epoch 6/25\n",
            "781/781 [==============================] - 607s 777ms/step - loss: 0.9968 - acc: 0.7924 - val_loss: 0.8162 - val_acc: 0.8326\n",
            "Epoch 7/25\n",
            "781/781 [==============================] - 607s 777ms/step - loss: 0.9656 - acc: 0.7951 - val_loss: 0.8227 - val_acc: 0.8238\n",
            "Epoch 8/25\n",
            "781/781 [==============================] - 614s 787ms/step - loss: 0.9574 - acc: 0.7989 - val_loss: 0.8413 - val_acc: 0.8126\n",
            "Epoch 9/25\n",
            "781/781 [==============================] - 622s 796ms/step - loss: 0.9632 - acc: 0.7991 - val_loss: 0.7649 - val_acc: 0.8337\n",
            "Epoch 10/25\n",
            "781/781 [==============================] - 607s 777ms/step - loss: 0.9474 - acc: 0.7982 - val_loss: 0.7960 - val_acc: 0.8231\n",
            "Epoch 11/25\n",
            "781/781 [==============================] - 599s 767ms/step - loss: 0.9801 - acc: 0.7987 - val_loss: 0.8502 - val_acc: 0.8246\n",
            "Epoch 12/25\n",
            "781/781 [==============================] - 594s 761ms/step - loss: 0.9697 - acc: 0.8002 - val_loss: 0.7862 - val_acc: 0.8195\n",
            "Epoch 13/25\n",
            "781/781 [==============================] - 598s 766ms/step - loss: 0.9634 - acc: 0.8010 - val_loss: 0.7688 - val_acc: 0.8317\n",
            "Epoch 14/25\n",
            "781/781 [==============================] - 591s 757ms/step - loss: 0.9495 - acc: 0.8038 - val_loss: 0.7976 - val_acc: 0.8325\n",
            "Epoch 15/25\n",
            "781/781 [==============================] - 591s 757ms/step - loss: 0.9844 - acc: 0.8005 - val_loss: 0.9576 - val_acc: 0.7856\n",
            "Epoch 16/25\n",
            "781/781 [==============================] - 592s 758ms/step - loss: 0.9691 - acc: 0.7993 - val_loss: 1.0060 - val_acc: 0.7947\n",
            "Epoch 17/25\n",
            "781/781 [==============================] - 591s 757ms/step - loss: 0.9690 - acc: 0.8008 - val_loss: 0.8523 - val_acc: 0.8179\n",
            "Epoch 18/25\n",
            "781/781 [==============================] - 592s 758ms/step - loss: 0.9764 - acc: 0.8008 - val_loss: 0.8595 - val_acc: 0.8156\n",
            "Epoch 19/25\n",
            "781/781 [==============================] - 594s 760ms/step - loss: 0.9582 - acc: 0.7995 - val_loss: 0.8445 - val_acc: 0.8181\n",
            "Epoch 20/25\n",
            "781/781 [==============================] - 590s 755ms/step - loss: 0.9558 - acc: 0.8035 - val_loss: 0.8040 - val_acc: 0.8251\n",
            "Epoch 21/25\n",
            "781/781 [==============================] - 590s 755ms/step - loss: 0.9624 - acc: 0.8028 - val_loss: 0.7733 - val_acc: 0.8343\n",
            "Epoch 22/25\n",
            "781/781 [==============================] - 589s 755ms/step - loss: 0.9368 - acc: 0.8076 - val_loss: 0.7927 - val_acc: 0.8397\n",
            "Epoch 23/25\n",
            "781/781 [==============================] - 587s 752ms/step - loss: 0.9482 - acc: 0.8051 - val_loss: 0.7826 - val_acc: 0.8297\n",
            "Epoch 24/25\n",
            "781/781 [==============================] - 586s 751ms/step - loss: 0.9642 - acc: 0.8042 - val_loss: 0.8035 - val_acc: 0.8342\n",
            "Epoch 25/25\n",
            "781/781 [==============================] - 582s 745ms/step - loss: 0.9361 - acc: 0.8058 - val_loss: 0.8004 - val_acc: 0.8335\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f63fd008320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xkgc-2AAqqWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Accuracy=83%"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0McGaGDIrCkO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#testing\n",
        "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
        "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0])\n",
        "\n",
        "#                                                                                                                                                              https://appliedmachinelearning.blog/2018/03/24/achieving-90-accuracy-in-object-recognition-task-on-cifar-10-dataset-with-keras-convolutional-neural-networks/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kl_XVqeZw5CC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}